# memory_monitor.py
import psutil
import time
import threading
import requests
import json
from datetime import datetime
import pandas as pd

class MemoryMonitor:
    def __init__(self, process_name="python"):
        self.process_name = process_name
        self.memory_stats = {
            'startup': 0,
            'peak': 0,
            'predictions': [],
            'timestamps': [],
            'concurrent_peak': 0
        }
        self.current_concurrent = 0
        self.lock = threading.Lock()
        
    def find_app_process(self):
        """æ‰¾åˆ°è¿è¡Œçš„app.pyè¿›ç¨‹"""
        for proc in psutil.process_iter(['pid', 'name', 'cmdline']):
            try:
                if proc.info['cmdline'] and any('app.py' in cmd for cmd in proc.info['cmdline']):
                    return psutil.Process(proc.info['pid'])
            except (psutil.NoSuchProcess, psutil.AccessDenied):
                continue
        return None
    
    def start_monitoring(self, interval=2):
        """å¼€å§‹ç›‘æ§å†…å­˜ä½¿ç”¨"""
        self.process = self.find_app_process()
        if not self.process:
            print("âŒ æœªæ‰¾åˆ°è¿è¡Œçš„app.pyè¿›ç¨‹ï¼Œè¯·å…ˆå¯åŠ¨åº”ç”¨")
            return False
            
        print(f"ğŸ” å¼€å§‹ç›‘æ§è¿›ç¨‹: {self.process.pid}")
        self.memory_stats['startup'] = self.record_memory("startup")
        
        def monitor_loop():
            while True:
                try:
                    if not self.process.is_running():
                        print("âš ï¸ åº”ç”¨è¿›ç¨‹å·²åœæ­¢")
                        break
                    self.record_memory("background")
                    time.sleep(interval)
                except psutil.NoSuchProcess:
                    print("âš ï¸ è¿›ç¨‹ä¸å­˜åœ¨")
                    break
        
        self.monitor_thread = threading.Thread(target=monitor_loop)
        self.monitor_thread.daemon = True
        self.monitor_thread.start()
        return True
    
    def record_memory(self, event="runtime"):
        """è®°å½•å†…å­˜ä½¿ç”¨"""
        try:
            memory_mb = self.process.memory_info().rss / 1024 / 1024
            
            with self.lock:
                self.memory_stats['timestamps'].append({
                    'time': datetime.now().isoformat(),
                    'memory_mb': memory_mb,
                    'event': event,
                    'concurrent': self.current_concurrent
                })
                
                if memory_mb > self.memory_stats['peak']:
                    self.memory_stats['peak'] = memory_mb
                
                # è®°å½•å¹¶å‘å³°å€¼
                if self.current_concurrent > 0 and memory_mb > self.memory_stats['concurrent_peak']:
                    self.memory_stats['concurrent_peak'] = memory_mb
            
            return memory_mb
        except psutil.NoSuchProcess:
            return 0
    
    def record_concurrent_start(self):
        """è®°å½•å¹¶å‘è¯·æ±‚å¼€å§‹"""
        with self.lock:
            self.current_concurrent += 1
    
    def record_concurrent_end(self, memory_used):
        """è®°å½•å¹¶å‘è¯·æ±‚ç»“æŸ"""
        with self.lock:
            self.current_concurrent -= 1
            self.memory_stats['predictions'].append(memory_used)
    
    def get_realtime_stats(self):
        """è·å–å®æ—¶ç»Ÿè®¡"""
        if not self.memory_stats['timestamps']:
            return "æ— æ•°æ®"
            
        current = self.memory_stats['timestamps'][-1]['memory_mb']
        return f"å½“å‰: {current:.1f}MB | å³°å€¼: {self.memory_stats['peak']:.1f}MB | å¹¶å‘å³°å€¼: {self.memory_stats['concurrent_peak']:.1f}MB"
    
    def generate_deployment_report(self):
        """ç”Ÿæˆéƒ¨ç½²æŠ¥å‘Š"""
        if not self.memory_stats['predictions']:
            return "**ğŸ“Š ç­‰å¾…æ”¶é›†æµ‹è¯•æ•°æ®...**"
        
        # è®¡ç®—ç»Ÿè®¡æ•°æ®
        avg_prediction = sum(self.memory_stats['predictions']) / len(self.memory_stats['predictions'])
        max_prediction = max(self.memory_stats['predictions']) if self.memory_stats['predictions'] else 0
        
        # å†…å­˜éœ€æ±‚è®¡ç®—
        base_memory = self.memory_stats['peak']
        safety_buffer = base_memory * 0.3  # 30%å®‰å…¨ç¼“å†²
        system_overhead = 200  # ç³»ç»Ÿå¼€é”€
        
        recommended_mb = base_memory + safety_buffer + system_overhead
        
        report = f"""
ğŸ¯ **å®é™…éƒ¨ç½²å†…å­˜éœ€æ±‚åˆ†ææŠ¥å‘Š**

ğŸ“Š **æµ‹è¯•æ•°æ®ç»Ÿè®¡**
â”œâ”€â”€ å¯åŠ¨å†…å­˜: {self.memory_stats['startup']:.1f} MB
â”œâ”€â”€ å³°å€¼å†…å­˜: {self.memory_stats['peak']:.1f} MB
â”œâ”€â”€ å¹¶å‘å³°å€¼: {self.memory_stats['concurrent_peak']:.1f} MB
â”œâ”€â”€ å¹³å‡è¯·æ±‚å†…å­˜: {avg_prediction:.1f} MB
â”œâ”€â”€ æœ€å¤§è¯·æ±‚å†…å­˜: {max_prediction:.1f} MB
â””â”€â”€ æ€»æµ‹è¯•æ¬¡æ•°: {len(self.memory_stats['predictions'])} æ¬¡

ğŸ’¡ **éƒ¨ç½²é…ç½®å»ºè®®**
â”œâ”€â”€ åŸºç¡€éœ€æ±‚: {int(base_memory)} MB
â”œâ”€â”€ å®‰å…¨ç¼“å†²: {int(safety_buffer)} MB (30%)
â”œâ”€â”€ ç³»ç»Ÿå¼€é”€: {system_overhead} MB
â”œâ”€â”€ **æ¨èé…ç½®**: {int(recommended_mb)} MB ({recommended_mb/1024:.1f} GB)
â””â”€â”€ ç”Ÿäº§ç¯å¢ƒ: {int(recommended_mb * 1.5)} MB ({recommended_mb * 1.5 / 1024:.1f} GB)

ğŸ”§ **è¯´æ˜**
- æµ‹è¯•ç¯å¢ƒ: å•æœºéƒ¨ç½²
- å¹¶å‘ç”¨æˆ·: æ¨¡æ‹Ÿ{self.memory_stats['timestamps'][-1]['concurrent'] if self.memory_stats['timestamps'] else 0}ä¸ª
- å»ºè®®åŸºäºå³°å€¼å†…å­˜ + 30%ç¼“å†² + ç³»ç»Ÿå¼€é”€
        """
        
        return report
    
    def save_detailed_report(self, filename="memory_report.json"):
        """ä¿å­˜è¯¦ç»†æŠ¥å‘Š"""
        report = {
            'summary': {
                'peak_memory_mb': self.memory_stats['peak'],
                'concurrent_peak_mb': self.memory_stats['concurrent_peak'],
                'recommended_memory_mb': self.memory_stats['peak'] * 1.3 + 200,
                'test_count': len(self.memory_stats['predictions'])
            },
            'detailed_data': self.memory_stats
        }
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        print(f"ğŸ“„ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜: {filename}")